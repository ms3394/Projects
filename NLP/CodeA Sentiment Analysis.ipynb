{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IwR9ZLnqnyup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a32875ca-1803-49b8-c6b0-5d93d39c5909"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import os\n",
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk import *\n",
        "from nltk.stem.porter import *\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "import string\n",
        "from nltk import ngrams\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Nx7aZnQgn8_g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81f02948-79cf-4e75-c9d4-db08f0a2462c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0kYUq_1en6P1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec7c4f27-a7a3-4654-be46-3c8a673cd6e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['4731_8.txt', '3264_8.txt', '7935_8.txt', '7447_8.txt', '9327_8.txt']\n",
            "2000\n",
            "['9485_3.txt', '6435_3.txt', '9565_3.txt', '5093_3.txt', '4392_3.txt']\n",
            "2000\n"
          ]
        }
      ],
      "source": [
        "# Path to the folder\n",
        "data_path = '/content/drive/MyDrive/data4'\n",
        "data = os.listdir(data_path)\n",
        "\n",
        "positive_reviews = os.listdir('/content/drive/MyDrive/data4/pos')\n",
        "negative_reviews = os.listdir('/content/drive/MyDrive/data4/neg')\n",
        "\n",
        "print(positive_reviews[:5])\n",
        "print(len(positive_reviews))\n",
        "print(negative_reviews[:5])\n",
        "print(len(negative_reviews))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xEf_oUdXoF_Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69bd9e4e-5c00-4cf6-a68a-3026bb598da3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(\"This is definitely one of Jet's best efforts. Few actors are able to play the stoic as Jet Li can. The action is rapid-fire, and special-effects boosted for intensity purposes. As a result, it may take Americans a little off-guard. A little suspension of disbelief goes a long way in a Jet Li film. I feel that it is an excellent introduction to Jet's work and look forward to further masterpieces (especially Fist of Legend) making it into the US market. A nice mixture of gunplay and physical conflict will satisfy most action flick enthusiasts.\", 'positive', 8), ('What a loss the passing of director Emile Ardolino was! He could take a light script and, with the right casting and editing, put a twinkle in it and make it shine like a star. This particular star may not be the brightest in the sky as great romances go, but it is definitely one that keeps you tuned in to the end. You really want to know how things are going to work out.<br /><br />The script is perfect for Cybill Shepherd, who at the time needed to capitalize on her \"Moonlighting\" success for the new generation who was (fortunately for her) probably unaware of how many big screen major duds she had after a very promising start. In this film she\\'s every bit back in form as a still-pining widow living vicariously through her daughter (Mary Stuart Masterson on the cusp of stardom which would peak with \"Fried Green Tomatoes\" two years later). She may have looked too young for the role, but that works well for the way the story unfolds. This is her film, but she doesn\\'t overstep her bounds as a lead.<br /><br />SHepherd graciously allows Robert Downey Jr. to carry much of the film and shows a more mature comic flair than he had in his previous films to that point. And there\\'s ample support from Ryan O\\'Neal (in his best role in years) and Christopher MacDonald. Masterson\\'s natural charm pretty much coasts on its own, either that or she has a way of making her character seem like a breath of fresh air with every word.<br /><br />Ardolino makes good use of his cast\\'s sex appeal the same way he did with \"Dirty Dancing\", but this film is not quite as sizzling so you could still watch it with your parents if they happened to be in the room. (Use your best judgment, they\\'re your parents after all.) I give this film a high mark because it is very user friendly, romantic comedy enthusiasts will find it sublime, and those who are just watching along with them should find plenty of humor to enjoy as well.<br /><br />Again, credit goes to Emile Ardolino for making the most of a charming script by Randy and Perry Howze. (Where are they now?) Ardolino\\'s next film would be the phoned-in sequel to \"Three Men and A Baby\" but his final theatrical release (Sister Act) would finally give him the nine-figure-grossing smash hit he deserved. Mr. Ardolino, your cinematic touch IS missed!', 'positive', 8), ('Hood of the Living Dead had a lot to live up to even before the opening credits began. First, any play on \"...of the living dead\" invokes His Holiness Mr. Romero and instantly sets up a high standard to which many movies cannot afford to aspire. And second, my movie-watching companion professed doubt that any urban horror film would surpass the seminal Leprechaun In the Hood. Skeptical, we settled in to watch. <br /><br />We were rewarded with a surprisingly sincere and good-hearted zombie film. Oh, certainly the budget is low, and of course the directors\\' amateurs friends populate the cast, but Hood of the Living Dead loves zombie cinema. Cheap? Yeah. But when it\\'s this cheap, you can clearly see where LOVE holds it together. <br /><br />Ricky works in a lab during the day and as a surrogate parent to his younger brother at night. He dreams of moving out of Oakland. Before this planned escape, however, his brother is shot to death in a drive-by. Ricky\\'s keen scientific mind presents an option superior to CPR or 911: injections of his lab\\'s experimental regenerative formula. Sadly, little bro wakes up in an ambulance as a bloodthirsty Oakland zombie! Chaos and mayhem! I think it\\'s more economical to eat your enemies than take vengeance in a drive-by, but then again, I\\'m a poor judge of the complexities of urban life. (How poor a judge? In response to a gory scene involving four men, I opined \"Ah-ha! White t-shirts on everyone so the blood shows up. Economical! I used the same technique in my own low-budget horror film.\" Jordan replied, \"No, that\\'s gang dress. White t-shirts were banned from New Orleans bars for a time as a result.\" Oh.)<br /><br />A lot of the movie is set in someone\\'s living room, so there\\'s a great deal of hanging out and waiting for the zombies. But the characters are sympathetic and the movie is sincere-- it surpasses its budget in spirit. <br /><br />Zombie explanation: When man plays God, zombies arise! Or, perhaps: Follow FDA-approved testing rules before human experimentation! <br /><br />Contribution to the zombie canon: This is the first zombie movie I\\'ve seen with a drive-by shooting. As far as the actual zombies go, infection is spread with a bite as usual, but quite unusually head shots don\\'t work-- it\\'s heart shots that kill. Zombies have pulses, the absence of which proves true death. And these zombies make pretty cool jaguar-growl noises. <br /><br />Gratuitous zombie movie in-joke: A mercenary named Romero. Groan. <br /><br />Favorite zombie: Jaguar-noise little brother zombie, of course!', 'positive', 8), ('The film maybe goes a little far, but if you love the show it\\'s what you expect. It\\'s not a bad movie; it\\'s actually pretty good. If you don\\'t like the show, don\\'t see the movie. It starts off a little slow maybe, but then picks up and turns out to be pretty funny. There are even a few \"heart-wrenching\" scenes toward the end. After all the protagonists have gone through these scences do get to you. Also Jerry throws in his opinion why his show upsets people and justifies his show\\'s existience. He\\'s got a pretty good point. We care so much about the private details of celebrities lives, so why is it wrong that these people tell their private lives on national TV, too. If they were celebrities we wouldn\\'t mind at all, we\\'d eat it up. Do we not like his guest doing this just because they\\'re poor white trash and it reminds us that there really is poverty in this world and not just rich glamous movie stars living in a \"Leave it to Beaver\" world?', 'positive', 8), (\"I am writing this after just seeing The Perfect Son at the 2002 Gay and Lesbian Mardi Gras Film Festival in Sydney, Australia.<br /><br />When their Father dies, two estranged brothers meet at the funeral and after discovering that one of the brothers is dying from AIDS, they enter on a heart warming journey of reconciliation. The two leads do a magnificent job of creating the gradual warmth and respect that builds up between them as the movie progresses. I do have one qualm about the movie though - whilst the brother who is dying acts sick, he doesn't look it. A person of 0 T4 cells would look quite ill - not even a make up job to make the actor look ill was employed. A small gripe, but one that makes it a bit less realistic. Despite that one small gripe, The Perfect Son is a wonderful movie and should you have the chance to see it- do. I'm hoping for a DVD release in the near future!\", 'positive', 8), ('This is a great example of a good, dumb movie. No, it is not high art by any means. Nor is the script anywhere close to a Woody Allen or Mel Brooks. BUT SO WHAT! The Killer Tomatoes series (four movies and a cartoon series) are basically good-natured romps gleefully trampling on the kind of territory the Zuckers ruled before they switched to making serious flicks.<br /><br />As the title suggests, this fourth installment of the Killer Tomatoes trilogy deals with the Killer Tomatoes plot against France. In this case, Professor Gangrene (John Astin\\'s 3rd time in the role) has a plan to rule France through an ancient prophecy about the return of the rightful King of France. Steve Lundquist returns as Igor, a humanoid tomato who wants to be a sportscaster and who just happens to be a dead ringer for the long-lost true King of France. Obviously he also plays the aforementioned l-l t K of F, happily skewering the French language.<br /><br />Opposing them is the fearless Fuzzy Tomato (like the others, FT was introduced in the second film and would be a main character in the cartoon) and his human allies. Mark Price, recently unemployed as a result of the conclusion of the FAMILY TIES series, plays a thinly disguised version of himself, passing himself as \"Michael J Fox\" as a way to win the girl of his dreams. And Angela Visser is a dream as Marie, gleefully bouncing between unabashed virginal sexuality and borderline psychosis. Oh that the former Miss Netherlands had had more of a film career! Another returning member of the Killer Tomatoes stock company is Rick Rockwell (now best known as the hapless title subject of \"Who Wants to Marry a Millionaire?\"). Like co-creator John De Bello, Rockwell works both in front of and behind the camera in this series.<br /><br />What can you say about Jon De Bello? Not much, really, except that he had a singular vision and managed to pull it off and, having done that, has apparently dropped into obscurity. John, if you ever see this, thanks for giving us the Killer Tomatoes.<br /><br />The script is heavily but not obnoxiously aware that this is just a movie. Like RETURN OF THE KILLER TOMATOES, the action occasionally veers off the set and into the middle of the film crew. And Mark Price has a funny forum to complain about his own lack of success compared to his former costar Michael J Fox. This is the biggest budgeted of all the Killer Tomatoes flicks and is a nice send-off to the series. Okay, the show then moved to Fox Kids as a cartoon series (which was also quite clever), but cartoons just aren\\'t the same.', 'positive', 8), ('For a movie with a plot like this I would normally smell \"tearjerker\" in the first ten minutes and turn it off, but this was very well made, with emotional subtleties, great acting, and some genuinely funny moments. It was also interesting to see a different culture - a vanishing one at that. My wife and I both dug it!', 'positive', 8), ('The 60\\'s is a great movie(I saw it completely in one night) about the hippy movement in the late 60\\'s. Although the title would suggest otherwise the first 5 years of the 60\\'s are not really important in this film.<br /><br />The main character of the movie is Michael,a political activist who goes on the road in the US against the Vietnam-war. There he meets his girlfriend,Sarah.Michael\\'s brother,Brian,goes to Vietnam to fight(what a surprise!).He comes back from the war and changes in a \"Tom Cruise Born on the fourth of July\" look a like and then into a Hippy.His dad is a pro-vietnam war type of guy(what a surprise!!).Michael\\'s sister Kate gets pregnant from a Rock & Roll artist and runs away from home and goes to San Francisco during the summer of love. The ending is very poor(father becomes a liberal and everybody is happy),but I let this slip away from my vote(the rest of the movie is very good!). <br /><br />The performances by the actors are pretty good and the soundtrack of the movie is absolutely brilliant. All the main events of the sixties are in the movie,like the murders on JFK and Martin Luther King aswell as the big hippy protests,the summer of love and Woodstock! Look closely for Wavy\"Woodstock Speaker\"Gravy(What we have in mind is breakfast in bed for 400.000!) as a first aid employee at the Woodstock festival!<br /><br />In the end,the 60\\'s is a beautiful movie about a beautiful decade! 10/10', 'positive', 8), (\"A meteor drops from the sky and reawakens a plesiosaur that long ago used to terrorize the area around Crater Lake . As the monster eats the locals they try and find away of killing the monster.<br /><br />Recent attempts at sending up old horror and science fiction films like Lost Skeleton of Cadavra and Alien Trespass are kind of rendered moot when you have films like Crater Lake Monster available for screening. It's the sort of film that those films spoof and send up only this is the real deal. Its everything those films try to be only with out the tongue in cheek and its so much more fun because of it. This is a real drive-in sort of film that had the unfortunate luck of coming just as Star Wars changed the way we look at special effects. The monster, a mix of stop motion and a life size head, is a charmingly quaint little beast. The filmmakers spoil the audience with frequent shots of the monster and its mayhem. Sure its clear that its all fake, but isn't movies about suspension of disbelief? Actually I think its about really cool monsters, which this has.<br /><br />I like this movie in a low budget drive in sort of a way. If you want a real authentic drive in monster movie look no farther. This would be perfect for a double or triple feature with similar lake monster films (Boggy Creek etc.)\", 'positive', 8), (\"This was a must see documentary for me when I missed the opportunity in 2004, so I was definitely going to watch the repeat. I really sympathised with the main character of the film, because, this is true, I have a milder condition of the skin problem he had, Dystrophic Epidermolysis Bullosa (EB). This is a sad, sometimes amusing and very emotional documentary about a boy with a terrible skin disorder. Jonny Kennedy speaks like a kid (because of wasting vocal muscle) and never went through puberty, but he is 36 years old. Most sympathising moments are seeing his terrible condition, and pealing off his bandages. Jonny had quite a naughty sense of humour, he even narrated from beyond the grave when showing his body in a coffin. He tells his story with the help of his mother, Edna Kennedy, his older brother and celebrity model, and Jonny's supporter, Nell McAndrew. It won the BAFTAs for Best Editing and Best New Director (Factual), and it was nominated for Best Sound (Factual) and the Flaherty Documentary Award. It was number 10 on The 100 Greatest TV Treats 2004. A must see documentary!\", 'positive', 8), ('It\\'s a strange feeling to sit alone in a theater occupied by parents and their rollicking kids. I felt like instead of a movie ticket, I should have been given a NAMBLA membership.<br /><br />Based upon Thomas Rockwell\\'s respected Book, How To Eat Fried Worms starts like any children\\'s story: moving to a new town. The new kid, fifth grader Billy Forrester was once popular, but has to start anew. Making friends is never easy, especially when the only prospect is Poindexter Adam. Or Erica, who at 4 1/2 feet, is a giant.<br /><br />Further complicating things is Joe the bully. His freckled face and sleeveless shirts are daunting. He antagonizes kids with the Death Ring: a Crackerjack ring that is rumored to kill you if you\\'re punched with it. But not immediately. No, the death ring unleashes a poison that kills you in the eight grade.<br /><br />Joe and his axis of evil welcome Billy by smuggling a handful of slimy worms into his thermos. Once discovered, Billy plays it cool, swearing that he eats worms all the time. Then he throws them at Joe\\'s face. Ewww! To win them over, Billy reluctantly bets that he can eat 10 worms. Fried, boiled, marinated in hot sauce, squashed and spread on a peanut butter sandwich. Each meal is dubbed an exotic name like the \"Radioactive Slime Delight,\" in which the kids finally live out their dream of microwaving a living organism.<br /><br />If you\\'ve ever met me, you\\'ll know that I have an uncontrollably hearty laugh. I felt like a creep erupting at a toddler whining that his \"dilly dick\" hurts. But Fried Worms is wonderfully disgusting. Like a G-rated Farrelly brothers film, it is both vomitous and delightful.<br /><br />Writer/director Bob Dolman is also a savvy storyteller. To raise the stakes the worms must be consumed by 7 pm. In addition Billy holds a dark secret: he has an ultra-sensitive stomach.<br /><br />Dolman also has a keen sense of perspective. With such accuracy, he draws on children\\'s insecurities and tendency to exaggerate mundane dilemmas.<br /><br />If you were to hyperbolize this movie the way kids do their quandaries, you will see that it is essentially about war. Freedom-fighter and freedom-hater use pubescent boys as pawns in proxy wars, only to learn a valuable lesson in unity. International leaders can learn a thing or two about global peacekeeping from Fried Worms.<br /><br />At the end of the film, I was comforted when two chaperoning mothers behind me, looked at each other with befuddlement and agreed, \"That was a great movie.\" Great, now I won\\'t have to register myself in any lawful databases.', 'positive', 8), ('Bizarre horror movie filled with famous faces but stolen by Cristina Raines (later of TV\\'s \"Flamingo Road\") as a pretty but somewhat unstable model with a gummy smile who is slated to pay for her attempted suicides by guarding the Gateway to Hell! The scenes with Raines modeling are very well captured, the mood music is perfect, Deborah Raffin is charming as Cristina\\'s pal, but when Raines moves into a creepy Brooklyn Heights brownstone (inhabited by a blind priest on the top floor), things really start cooking. The neighbors, including a fantastically wicked Burgess Meredith and kinky couple Sylvia Miles & Beverly D\\'Angelo, are a diabolical lot, and Eli Wallach is great fun as a wily police detective. The movie is nearly a cross-pollination of \"Rosemary\\'s Baby\" and \"The Exorcist\"--but what a combination! Based on the best-seller by Jeffrey Konvitz, \"The Sentinel\" is entertainingly spooky, full of shocks brought off well by director Michael Winner, who mounts a thoughtfully downbeat ending with skill. ***1/2 from ****', 'positive', 8), (\"A great Bugs Bunny cartoon from the earlier years has Bugs as a performer in an window display at a local department store. After he's done for the day the manager comes in to tell him that he'll be transferring soon. Bugs is happy to oblige into he figures out that the new job is in taxidermy...and that taxidermy has to do with stuffing animals. Animals like say, a certain rabbit. This causes a battle of wits between the rascally rabbit and his now former employer. I found this short to be delightful and definitely one of the better ones of the early 1940's. It still remains as funny nearly 60+ years later. This animated short can be seen on Disc 1 of the Looney Tunes Golden Collection Volume 2.<br /><br />My Grade: A-\", 'positive', 8), ('This is one of those Film\\'s/pilot that if you knew BattleStar Galactica it helps, but isn\\'t necessary. What makes this even more believable of a story than BSG is that this isn\\'t something so far away in the future. This has such a depth to it that it is quite astonishing it was not released theatrically. The leads could not have been chosen better in such experienced & quite talented actors. Eric Stoltz is superb as the father who will do anything to be re-united w/his daughter however real or not she is & he\\'ll do it no matter the cost. Paula Malcomson of \"Deadwood\" fame is terrific as his wife as well. You are not sure completely of his motives whether it\\'s love or money or both, but that is what makes this pilot even more intriguing. I see a star in the making of Zoe played by the relative unknown Alessandra Torresani & her performance. Esai Morales is terrific in his desire to see his loved one again & just how wrong to be even considering what he wants more than his moral objections. I didn\\'t think this would be a good idea when it was announced but from the pilot alone I am thrilled to see how we got to the BSG stage story. It\\'s great to see Adama as a child already being affected & influenced by the different sorts of Robots starting to permeate life at this stage. I just hope that they can keep up the stories so we can figure out even more how they got the the Humanoid typed robots. This is an almost perfect pilot & I hope they can keep up the fantastic storytelling. Even the Visual effects are better than most of the garbage you see on the big screen. If you haven\\'t gotten into BSG, @ least try this & I\\'ll bet you become a fan & will want to see how the BSG story came to be.', 'positive', 8), (\"After the usual chase scene, Jerry accidentally winds up inside a bottle of invisible ink, which was part of a chemistry set. He quickly discovers he's invisible...so the predictable results occur, meaning he uses his new hidden condition to torment Tom. Jerry often is just defending himself, but often he has sadistic streak in him that torments the cat whenever possible, even when unprovoked.<br /><br />Here, he makes Tom think his eyes are deceiving him when cheese from a mousetrap disappears before his eyes, or milk from a dish. Tom can't take anymore so he tries to sleep this nightmare off, but Jerry sets fire to his paw! Man, I hope little kids didn't ideas watching these cartoons back in the '40s and '50s! I always found Jerry, the little mouse, more evil than cute.<br /><br />Thankfully, in cartoons, generally, whatever damage a character suffers is gone within seconds and he's back to normal. <br /><br />The best part of this cartoon is about two-thirds of the way through when Tom figures out what the story is with Jerry, and tries different methods to detect where the mouse is located (such as putting flour on the floor to see his footprints).\", 'positive', 8), (\"Pierce Brosnan the newest but no longer James Bond, is an assassin. He is very very good at what he does, but he's getting old and tired. Greg Kinnair is really good as the straight and narrow business man. Now when the story opens the movie shows these two people in their separate lives. Then one night they are having drinks in a bar, and they begin to talk. Then all of a sudden you find these two people getting drawn together during a series of events. The story is excellent, the acting is top notch, and the humor is hilarious I never thought that Pierce Brosnan would be this funny, but he really is and I must say this movie is a must see.\", 'positive', 8), ('James Stewart stars in a classic western tale of revenge which ties in with the fate of the films other star the Winchester Rifle. Stewart is it goes without saying excellent adding some cold hard obsession to his usual laid back cowboy. The story follows the fate of a Winchester rifle and its owners after being won in a competition by our hero and stolen by the man he is hunting.<br /><br />We meet a selection of gamblers, gun fighters, Indian traders and bank robers as we follow the rifles path through Indian battles, bank heists etc. The supporting cast are all solid with Dan Durya standing out as Waco Johnny Dean the live-wire gunfighter with an itchy trigger finger. Also as a trivia note a very early appearance from Rock Hudson as an Indian chief.<br /><br />The end showdown is a classic a tense rifle battle fought at long range in and around a rocky outcrop. Throw in some good old western action, fist fights, shootouts and horseback chases it makes for a rollicking western adventure. 8/10', 'positive', 8), (\"Steve Carell has made a career out of portraying the slightly odd straight guy, first on 'The Daily Show', and then in various supporting roles. In Virgin, Carell has found a clever and hilarious script that perfectly capitalizes on his strengths. Carell plays Andy Stitzer, a middle aged man living a quiet, lonely life. Andy is a little odd, but in an awkward nice guy sort of way. One night, while socializing with his co-workers for the first time, Andy accidentally reveals that he is a virgin. His co-workers, David (Paul Rudd), Jay (Romany Malco), and Cal (Seth Rogen) initially tease Andy about his situation. But it's clear that all three have a certain respect for the decent human being that Andy is, and they resolve to help him out by assisting him in ending his virginity. And so begins Andy's quest into adulthood. Andy is the quintessential innocent, and the bulk of the humor derives from his naivet√© to the situations he finds himself in throughout the film. Some of the humor is crude gross out stuff, but most of it is just well done intelligent comedy. In addition, I found some parts of the film actually pretty touching as Andy finds himself developing both romantic relationships and friendships perhaps for the first time in his life. I'm not trying to portray the movie as a love story or a drama; it's a rolling in your seats comedy. Still, every good comedy I have ever seen contains enough heart for you to care about the characters. A good comparison would be 'The Wedding Crashers' from earlier this summer. Virgin has a similar humor, but is perhaps a bit more vulgar in some of its jokes. I particularly loved the ending of the film, which I thought was a perfect way to end the flick. Without giving anything away, it reminded me of 'Something About Mary'. Very light and fun; it leaves you laughing and smiling, which is exactly how you should feel when you finish a comedy. I would highly recommend.\", 'positive', 8), ('My evaluation: 8/10<br /><br />I like a lot this movie. Compare to today brainless movie (just action and special effet and nothing new about ideas), \"Soylent Green\" ask to something that today doesn\\'t exist anymore: To Think.<br /><br />Well it would not a big surprise a day human eat \"cookies\" which are create with body of human. With all what happen on this planet, and to see how people are so indifferent to all, this kind of future is possible.<br /><br />Sure this movie take some age but the idea behind the movie is actual again. Rich at Paradise, other in the hell. Well a luck today they are TV and idiocy like \"Reality Show\".<br /><br />TV is a good wash brain. It\\'s pity to see that intelligence of human have not progress like technologies. Since writing all stop.<br /><br />If you like reality show this movie is not for you. If you believe all politician same too. If you don\\'t like ask yourself question about now and future well never look this movie.', 'positive', 8), (\"One night I stumbled upon this on the satellite station Bravo.Initially out of curiosity i decided to watch it.To be perfectly honest i wasn't disappointed.The main character is beautiful and her body is shown off well.You would think her talents would be wasted as a executioner but apparently not after watching the whole film!My only real gripe is the acting of the supporting cast particularly the actor who plays Melnik.Christ its bad!The prison guard Hank is woeful too.All he ever does is get drunk and make ill attempted passes at his co-guard Wanda though fortunately for us the viewer and for Hank he gets down and dirty with Wanda near the end. The music used is pretty tense and creates the perfect atmosphere for the executions. This movie is well watching alone for the beautiful,talented and very sexy Jennifer Thomas\", 'positive', 8)]\n",
            "2000\n",
            "2000\n"
          ]
        }
      ],
      "source": [
        "def load_data(path, label):\n",
        "    data = []\n",
        "\n",
        "    for filename in os.listdir(path):\n",
        "        file_path = os.path.join(path, filename)\n",
        "\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            content = file.read()\n",
        "\n",
        "            # Extracting star rating using regular expression\n",
        "            match = re.search(r'_(\\d+)\\.txt$', filename)\n",
        "            star_rating = int(match.group(1)) if match else 0\n",
        "\n",
        "            data.append((content, label, star_rating))\n",
        "\n",
        "    return data\n",
        "\n",
        "# Load positive reviews\n",
        "positive_reviews = load_data('/content/drive/MyDrive/data4/pos', 'positive')\n",
        "print(positive_reviews[:20])\n",
        "print(len(positive_reviews))\n",
        "\n",
        "# Load negative reviews\n",
        "negative_reviews = load_data('/content/drive/MyDrive/data4/neg', 'negative')\n",
        "print(len(negative_reviews))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TQ7qy1kNoKr2"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "TotalDataset = positive_reviews + negative_reviews\n",
        "\n",
        "data = [review[0] for review in TotalDataset]\n",
        "labels = [label[1] for label in TotalDataset]\n",
        "\n",
        "#Spillting the data into 80-10-10\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "X_dev, X_test, y_dev, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vkIh4fRepHXV"
      },
      "outputs": [],
      "source": [
        "#Combination 1\n",
        "def process_one(data_list):\n",
        "  stoplist = set(stopwords.words('english'))\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  tokenized_list = []\n",
        "  for content in data_list:\n",
        "    #list comprehension\n",
        "    word_list = [lemmatizer.lemmatize(word) for word in word_tokenize(content.lower())\n",
        "                 if not word in stoplist]\n",
        "    tokenized_list.append(word_list)\n",
        "  return tokenized_list\n",
        "\n",
        "training_feature_selection_one = process_one(X_train)\n",
        "dev_feature_selection_one = process_one(X_dev)\n",
        "test_feature_selection_one = process_one(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2UaxI3z9oPQE"
      },
      "outputs": [],
      "source": [
        "#Combination two\n",
        "def process_two(data_list):\n",
        "    stoplist = set(stopwords.words('english'))\n",
        "    st = PorterStemmer()\n",
        "    tokenized_list = []\n",
        "    for content in data_list:\n",
        "        word_list = [st.stem(re.sub(r'[^a-zA-Z0-9]', '', word)) for word in word_tokenize(content.lower()) if not word in stoplist and not re.match(r'[^a-zA-Z0-9]+', word)]\n",
        "        tokenized_list.append(word_list)\n",
        "\n",
        "    return tokenized_list\n",
        "\n",
        "training_feature_selection_two = process_two(X_train)\n",
        "dev_feature_selection_two = process_two(X_dev)\n",
        "test_feature_selection_two = process_two(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Combination three\n",
        "def process_three(data_list):\n",
        "    tokenized_list = []\n",
        "    st = PorterStemmer()\n",
        "    for content in data_list:\n",
        "        word_list = [st.stem(re.sub(r'[^a-zA-Z0-9]', '', word)) for word in word_tokenize(content.lower()) if not re.search(r'[^a-zA-Z0-9]+', word)]\n",
        "        tokenized_list.append(word_list)\n",
        "    return tokenized_list\n",
        "\n",
        "training_feature_selection_three = process_three(X_train)\n",
        "dev_feature_selection_three = process_three(X_dev)\n",
        "test_feature_selection_three = process_three(X_test)"
      ],
      "metadata": {
        "id": "c-QO2MzwhVQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VT5UIJQEqlJ-"
      },
      "outputs": [],
      "source": [
        "def calculate_ngrams(data_list):\n",
        "    ngrams_list = []\n",
        "    for content in data_list:\n",
        "        n_grams = list(ngrams(content,2))\n",
        "        grams_string = [' '.join(gram) for gram in n_grams]\n",
        "        ngrams_list.append(grams_string)\n",
        "    return ngrams_list\n",
        "\n",
        "#Process 1\n",
        "train_ngrams_one = calculate_ngrams(training_feature_selection_one)\n",
        "dev_ngrams_one = calculate_ngrams(dev_feature_selection_one)\n",
        "test_ngrams_one = calculate_ngrams(test_feature_selection_one)\n",
        "\n",
        "#Process 2\n",
        "train_ngrams_two = calculate_ngrams(training_feature_selection_two)\n",
        "dev_ngrams_two = calculate_ngrams(dev_feature_selection_two)\n",
        "test_ngrams_two = calculate_ngrams(test_feature_selection_two)\n",
        "\n",
        "#Process 3\n",
        "train_ngrams_three = calculate_ngrams(training_feature_selection_three)\n",
        "dev_ngrams_three = calculate_ngrams(dev_feature_selection_three)\n",
        "test_ngrams_three = calculate_ngrams(test_feature_selection_three)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sxvhuolRz9Zf"
      },
      "outputs": [],
      "source": [
        "# Trivial Normalisation\n",
        "def trivial_normalisation(ngrams_list):\n",
        "    trivial_list = []\n",
        "    for doc in ngrams_list:\n",
        "        frequencies = Counter(doc)\n",
        "        tf_dict = {gram: frequencies[gram]/ len(doc) for gram in doc}\n",
        "        trivial_list.append(tf_dict)\n",
        "    return trivial_list\n",
        "\n",
        "train_values_one = trivial_normalisation(train_ngrams_one)\n",
        "dev_values_one = trivial_normalisation(dev_ngrams_one)\n",
        "test_values_one = trivial_normalisation(test_ngrams_one)\n",
        "\n",
        "train_values_two = trivial_normalisation(train_ngrams_one)\n",
        "dev_values_two = trivial_normalisation(dev_ngrams_two)\n",
        "test_values_three = trivial_normalisation(test_ngrams_three)\n",
        "\n",
        "train_values_one = trivial_normalisation(train_ngrams_one)\n",
        "dev_values_two = trivial_normalisation(dev_ngrams_two)\n",
        "test_values_three = trivial_normalisation(test_ngrams_three)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "APifkgZYqv8q"
      },
      "outputs": [],
      "source": [
        "def calculate_all_tfidfs(ngrams_list):\n",
        "    def calculate_tfidf(gram, doc, doc_frequencies, num_docs):\n",
        "        frequencies = Counter(doc)\n",
        "        tf = frequencies[gram] / len(doc)\n",
        "        idf = np.log(num_docs / (doc_frequencies[gram] + 1))\n",
        "        return tf * idf\n",
        "\n",
        "    num_docs = len(ngrams_list)\n",
        "    doc_frequencies = Counter(gram for doc in ngrams_list for gram in set(doc))\n",
        "\n",
        "    allTfIDfs = []\n",
        "\n",
        "    for doc in ngrams_list:\n",
        "        tfIdfs = {gram: calculate_tfidf(gram, doc, doc_frequencies, num_docs) for gram in doc}\n",
        "        allTfIDfs.append(tfIdfs)\n",
        "\n",
        "    return allTfIDfs\n",
        "\n",
        "#Process one\n",
        "train_tfidf_values_one = calculate_all_tfidfs(train_ngrams_one)\n",
        "dev_tfidf_values_one = calculate_all_tfidfs(dev_ngrams_one)\n",
        "test_tfidf_values_one = calculate_all_tfidfs(test_ngrams_one)\n",
        "\n",
        "#Process two\n",
        "train_tfidf_values_two = calculate_all_tfidfs(train_ngrams_two)\n",
        "dev_tfidf_values_two = calculate_all_tfidfs(dev_ngrams_two)\n",
        "test_tfidf_values_two = calculate_all_tfidfs(test_ngrams_two)\n",
        "\n",
        "#Process three\n",
        "train_tfidf_values_three = calculate_all_tfidfs(train_ngrams_three)\n",
        "dev_tfidf_values_three = calculate_all_tfidfs(dev_ngrams_three)\n",
        "test_tfidf_values_three = calculate_all_tfidfs(test_ngrams_three)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xiLkfW_nsgq9"
      },
      "outputs": [],
      "source": [
        "def extract_unique_features(tfidf_values_list):\n",
        "    unique_features = set()\n",
        "\n",
        "    for tfidf_values in tfidf_values_list:\n",
        "        unique_features.update(tfidf_values.keys())\n",
        "\n",
        "    return list(unique_features)\n",
        "\n",
        "# Extract unique features from the TF-IDF values of the training set\n",
        "unique_features_one = extract_unique_features(train_tfidf_values_one)\n",
        "unique_features_two = extract_unique_features(train_tfidf_values_two)\n",
        "unique_features_three = extract_unique_features(train_tfidf_values_three)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27Tv1Jn1stQr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_tfidf_matrix(tfidf_values_list, unique_features):\n",
        "    num_docs = len(tfidf_values_list)\n",
        "    num_features = len(unique_features)\n",
        "    matrix = np.zeros((num_docs, num_features))\n",
        "\n",
        "    for i, tfidf_values in enumerate(tfidf_values_list):\n",
        "        matrix[i] = np.array([tfidf_values.get(feature, 0) for feature in unique_features])\n",
        "\n",
        "    return matrix\n",
        "\n",
        "#Process one\n",
        "train_tfidf_matrix_one = create_tfidf_matrix(train_tfidf_values_one, unique_features_one)\n",
        "dev_tfidf_matrix_one = create_tfidf_matrix(dev_tfidf_values_one, unique_features_one)\n",
        "test_tfidf_matrix_one = create_tfidf_matrix(test_tfidf_values_one, unique_features_one)\n",
        "\n",
        "#Process two\n",
        "train_tfidf_matrix_two = create_tfidf_matrix(train_tfidf_values_two, unique_features_two)\n",
        "dev_tfidf_matrix_two = create_tfidf_matrix(dev_tfidf_values_two, unique_features_two)\n",
        "test_tfidf_matrix_two = create_tfidf_matrix(test_tfidf_values_two, unique_features_two)\n",
        "\n",
        "#Process three\n",
        "train_tfidf_matrix_three = create_tfidf_matrix(train_tfidf_values_three, unique_features_three)\n",
        "dev_tfidf_matrix_three = create_tfidf_matrix(dev_tfidf_values_three, unique_features_three)\n",
        "test_tfidf_matrix_three = create_tfidf_matrix(test_tfidf_values_three, unique_features_three)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRa0UsAgLCur"
      },
      "outputs": [],
      "source": [
        "print(train_tfidf_matrix_one.shape)\n",
        "print(dev_tfidf_matrix_one.shape)\n",
        "print(test_tfidf_matrix_one.shape)\n",
        "\n",
        "print(train_tfidf_matrix_two.shape)\n",
        "print(dev_tfidf_matrix_two.shape)\n",
        "print(test_tfidf_matrix_two.shape)\n",
        "\n",
        "print(train_tfidf_matrix_three.shape)\n",
        "print(dev_tfidf_matrix_three.shape)\n",
        "print(test_tfidf_matrix_three.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToBHL4Qts7hE"
      },
      "outputs": [],
      "source": [
        "#Process one\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Create a Multinomial Naive Bayes classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "\n",
        "# Train the classifier\n",
        "nb_classifier.fit(train_tfidf_matrix_one, y_train)\n",
        "#Evaluating on the development matrix\n",
        "y_pred_one = nb_classifier.predict(dev_tfidf_matrix_one)\n",
        "accuracy_one = accuracy_score(y_dev, y_pred_one)\n",
        "print(f\"Combination one Accuracy: {accuracy_one}\")\n",
        "# ClassificationReport_one = classification_report(y_dev, y_pred_one)\n",
        "# print(f\"\\nCombination one Classification Report\\n: {ClassificationReport_one}\")\n",
        "\n",
        "#Evaluate on the test set\n",
        "test_y_pred_one = nb_classifier.predict(test_tfidf_matrix_one)\n",
        "test_accuracy_one = accuracy_score(y_test, test_y_pred_one)\n",
        "print(f\"Combination one Test Accuracy: {test_accuracy_one}\")\n",
        "# ClassificationReport_one = classification_report(y_test, test_y_pred_one)\n",
        "# print(f\"\\nCombination one Classification Report\\n: {ClassificationReport_one}\")\n",
        "\n",
        "#Process two\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "nb_classifier = MultinomialNB()\n",
        "\n",
        "nb_classifier.fit(train_tfidf_matrix_two, y_train)\n",
        "y_pred_two = nb_classifier.predict(dev_tfidf_matrix_two)\n",
        "\n",
        "accuracy_two = accuracy_score(y_dev, y_pred_two)\n",
        "print(f\"Combination two Accuracy: {accuracy_two}\")\n",
        "# ClassificationReport_two = classification_report(y_dev, y_pred_two)\n",
        "# print(f\"\\nCombination two Classification Report\\n: {ClassificationReport_two}\")\n",
        "\n",
        "#Evaluate on the test set\n",
        "test_y_pred_two = nb_classifier.predict(test_tfidf_matrix_two)\n",
        "test_accuracy_two = accuracy_score(y_test, test_y_pred_two)\n",
        "print(f\"Combination two Test Accuracy: {test_accuracy_two}\")\n",
        "# ClassificationReport_two = classification_report(y_test, test_y_pred_two)\n",
        "# print(f\"\\nCombination two Classification Report\\n: {ClassificationReport_two}\")\n",
        "\n",
        "#Process three\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "nb_classifier = MultinomialNB()\n",
        "\n",
        "nb_classifier.fit(train_tfidf_matrix_three, y_train)\n",
        "y_pred_three = nb_classifier.predict(dev_tfidf_matrix_three)\n",
        "\n",
        "accuracy_three = accuracy_score(y_dev, y_pred_three)\n",
        "ClassificationReport_three = classification_report(y_dev, y_pred_three)\n",
        "print(f\"Combination three Accuracy: {accuracy_three}\")\n",
        "# ClassificationReport_three = classification_report(y_dev, y_pred_three)\n",
        "# print(f\"\\nCombination three Classification Report\\n: {ClassificationReport_three}\")\n",
        "\n",
        "#Evaluate on the test set\n",
        "test_y_pred_three = nb_classifier.predict(test_tfidf_matrix_three)\n",
        "test_accuracy_three = accuracy_score(y_test, test_y_pred_three)\n",
        "print(f\"Combination three Test Accuracy: {test_accuracy_two}\")\n",
        "# ClassificationReport_two = classification_report(y_test, test_y_pred_three)\n",
        "# print(f\"\\nCombination three Classification Report\\n: {ClassificationReport_three}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from collections import defaultdict\n",
        "\n",
        "def calculate_prior(y_train):\n",
        "    class_counts = defaultdict(int)\n",
        "    for label in y_train:\n",
        "        class_counts[label] += 1\n",
        "    total_samples = len(y_train)\n",
        "    class_probabilities = {label: count / total_samples for label, count in class_counts.items()}\n",
        "    return class_probabilities\n",
        "\n",
        "def calculate_likelihood(tfidf_matrix, y_train):\n",
        "    class_counts = defaultdict(int)\n",
        "    feature_counts = defaultdict(lambda: defaultdict(float))\n",
        "\n",
        "    for i, label in enumerate(y_train):\n",
        "        class_counts[label] += 1\n",
        "        for j, value in enumerate(tfidf_matrix[i]):\n",
        "            feature_counts[label][j] += value\n",
        "\n",
        "    likelihoods = defaultdict(dict)\n",
        "    for label in class_counts:\n",
        "        total_samples_in_class = class_counts[label]\n",
        "        likelihoods[label] = {feature: count / total_samples_in_class for feature, count in feature_counts[label].items()}\n",
        "\n",
        "    return likelihoods\n",
        "\n",
        "def predict(tfidf_matrix, prior_probabilities, likelihoods):\n",
        "    predictions = []\n",
        "\n",
        "    # Precompute normalized likelihoods for each label\n",
        "    normalized_likelihoods = {label: {feature: count / sum(likelihoods[label].values()) for feature, count in likelihoods[label].items()} for label in prior_probabilities}\n",
        "\n",
        "    for sample in tfidf_matrix:\n",
        "        max_prob = float('-inf')\n",
        "        predicted_label = None\n",
        "\n",
        "        for label in prior_probabilities:\n",
        "            log_prob = sum([sample[feature] * normalized_likelihoods[label].get(feature, 0) for feature in range(len(sample))])\n",
        "            log_prob += prior_probabilities[label]\n",
        "\n",
        "            if log_prob > max_prob:\n",
        "                max_prob = log_prob\n",
        "                predicted_label = label\n",
        "\n",
        "        predictions.append(predicted_label)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "def calculate_accuracy(y_true, y_pred):\n",
        "    return accuracy_score(y_true, y_pred)\n",
        "\n",
        "\n",
        "prior_probabilities = calculate_prior(y_train)\n",
        "\n",
        "likelihoods_one = calculate_likelihood(train_tfidf_matrix_one, y_train)\n",
        "predictions_one = predict(dev_tfidf_matrix_one, prior_probabilities, likelihoods_one)\n",
        "accuracy_one = calculate_accuracy(y_dev, predictions_one)\n",
        "print(\"Accuracy for Combination one:\", accuracy_one)\n",
        "ClassificationReport_one = classification_report(y_dev, predictions_one)\n",
        "print(\"\\nClassification Report for Combination one\\n:\", ClassificationReport_one)\n",
        "\n",
        "likelihoods_two = calculate_likelihood(train_tfidf_matrix_two, y_train)\n",
        "predictions_two = predict(dev_tfidf_matrix_two, prior_probabilities, likelihoods_two)\n",
        "accuracy_two = calculate_accuracy(y_dev, predictions_two)\n",
        "print(\"Accuracy for Combination two:\", accuracy_two)\n",
        "ClassificationReport_two = classification_report(y_dev, predictions_two)\n",
        "print(\"\\nClassification Report for Combination two\\n:\", ClassificationReport_two)\n",
        "\n",
        "likelihoods_three = calculate_likelihood(train_tfidf_matrix_three, y_train)\n",
        "predictions_three = predict(dev_tfidf_matrix_three, prior_probabilities, likelihoods_three)\n",
        "accuracy_three = calculate_accuracy(y_dev, predictions_three)\n",
        "print(\"Accuracy for Combination three:\", accuracy_three)\n",
        "\n",
        "ClassificationReport_one = classification_report(y_dev, predictions_one)\n",
        "print(\"\\nClassification Report for Combination three\\n:\", ClassificationReport_one)"
      ],
      "metadata": {
        "id": "8BhmL8FNsPr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#Combination one\n",
        "model = LogisticRegression()\n",
        "model.fit(train_tfidf_matrix_one, y_train)\n",
        "\n",
        "# Evaluate on the development set\n",
        "dev_predictions_one = model.predict(dev_tfidf_matrix_one)\n",
        "logistic_regresion_accuracy_one = accuracy_score(y_dev, dev_predictions_one)\n",
        "print(f\"Logistic Regression Accuracy for Combination one: {logistic_regresion_accuracy_one}\")\n",
        "\n",
        "ClassificationReport_one = classification_report(y_dev, dev_predictions_one)\n",
        "print(f\"\\nCombination one Classification Report\\n: {ClassificationReport_one}\")\n",
        "\n",
        "#Evaluate on Test set\n",
        "test_predictions_one = model.predict(test_tfidf_matrix_one)\n",
        "logistic_regresion_test_accuracy_one = accuracy_score(y_test, test_predictions_one)\n",
        "print(f\"Logistic Regression Accuracy for Combination one: {logistic_regresion_test_accuracy_one}\")\n",
        "\n",
        "ClassificationReport_test_one = classification_report(y_test, test_predictions_one)\n",
        "print(f\"\\nCombination one Classification Report\\n: {ClassificationReport_test_one}\")\n",
        "\n",
        "#Combination two\n",
        "model = LogisticRegression()\n",
        "model.fit(train_tfidf_matrix_two, y_train)\n",
        "\n",
        "# Evaluate on the development set\n",
        "dev_predictions_two = model.predict(dev_tfidf_matrix_two)\n",
        "logistic_regresion_accuracy_two = accuracy_score(y_dev, dev_predictions_two)\n",
        "print(f\"Logistic Regression Accuracy for Combination two: {logistic_regresion_accuracy_two}\")\n",
        "\n",
        "ClassificationReport_two = classification_report(y_dev, dev_predictions_two)\n",
        "print(f\"\\nCombination one Classification Report\\n: {ClassificationReport_two}\")\n",
        "\n",
        "#Evaluate on Test set\n",
        "test_predictions_two = model.predict(test_tfidf_matrix_two)\n",
        "logistic_regresion_test_accuracy_two = accuracy_score(y_test, test_predictions_two)\n",
        "print(f\"Logistic Regression Accuracy for Combination one: {logistic_regresion_test_accuracy_two}\")\n",
        "\n",
        "ClassificationReport_test_two = classification_report(y_test, test_predictions_two)\n",
        "print(f\"\\nCombination one Classification Report\\n: {ClassificationReport_test_two}\")\n",
        "\n",
        "#Combination three\n",
        "model = LogisticRegression()\n",
        "model.fit(train_tfidf_matrix_three, y_train)\n",
        "\n",
        "# Evaluate on the development set\n",
        "dev_predictions_three = model.predict(dev_tfidf_matrix_three)\n",
        "logistic_regresion_accuracy_three = accuracy_score(y_dev, dev_predictions_three)\n",
        "print(f\"Logistic Regression Accuracy for Combination three: {logistic_regresion_accuracy_three}\")\n",
        "\n",
        "ClassificationReport_three = classification_report(y_dev, dev_predictions_three)\n",
        "print(f\"\\nCombination one Classification Report\\n: {ClassificationReport_three}\")\n",
        "\n",
        "#Evaluate on Test set\n",
        "test_predictions_three = model.predict(test_tfidf_matrix_three)\n",
        "logistic_regresion_test_accuracy_three = accuracy_score(y_test, test_predictions_three)\n",
        "print(f\"Logistic Regression Accuracy for Combination one: {logistic_regresion_test_accuracy_three}\")\n",
        "\n",
        "ClassificationReport_test_three = classification_report(y_test, test_predictions_three)\n",
        "print(f\"\\nCombination one Classification Report\\n: {ClassificationReport_test_three}\")"
      ],
      "metadata": {
        "id": "UG4WxF3TTrcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "#Combination one\n",
        "model = SVC()\n",
        "model.fit(train_tfidf_matrix_one, y_train)\n",
        "# Evaluate on the development set\n",
        "dev_predictions_one = model.predict(dev_tfidf_matrix_one)\n",
        "SVM_accuracy_one = accuracy_score(y_dev, dev_predictions_one)\n",
        "print(f\"SVM Accuracy for Combination one: {SVM_accuracy_one}\")\n",
        "\n",
        "ClassificationReport_one = classification_report(y_dev, dev_predictions_one)\n",
        "print(f\"\\nCombination one Classification Report\\n: {ClassificationReport_one}\")\n",
        "\n",
        "#Evaluate on Test set\n",
        "test_predictions_one = model.predict(test_tfidf_matrix_one)\n",
        "logistic_regresion_test_accuracy_one = accuracy_score(y_test, test_predictions_one)\n",
        "print(f\"SVM Accuracy for Combination one: {logistic_regresion_test_accuracy_one}\")\n",
        "\n",
        "ClassificationReport_test_one = classification_report(y_test, test_predictions_one)\n",
        "print(f\"\\nCombination one Classification Report\\n: {ClassificationReport_test_one}\")\n",
        "\n",
        "#Combination two\n",
        "model = SVC()\n",
        "model.fit(train_tfidf_matrix_two, y_train)\n",
        "dev_predictions_two = model.predict(dev_tfidf_matrix_two)\n",
        "SVM_accuracy_two = accuracy_score(y_dev, dev_predictions_two)\n",
        "print(f\"SVM Accuracy for Combination two: {SVM_accuracy_two}\")\n",
        "\n",
        "ClassificationReport_two = classification_report(y_dev, dev_predictions_two)\n",
        "print(f\"\\nCombination two Classification Report\\n: {ClassificationReport_two}\")\n",
        "\n",
        "#Evaluate on Test set\n",
        "test_predictions_two = model.predict(test_tfidf_matrix_two)\n",
        "logistic_regresion_test_accuracy_two = accuracy_score(y_test, test_predictions_two)\n",
        "print(f\"SVM Regression Test Accuracy for Combination two: {logistic_regresion_test_accuracy_two}\")\n",
        "\n",
        "ClassificationReport_test_two = classification_report(y_test, test_predictions_two)\n",
        "print(f\"\\nCombination two Classification Report\\n: {ClassificationReport_test_two}\")\n",
        "\n",
        "#Combination three\n",
        "model = SVC()\n",
        "model.fit(train_tfidf_matrix_three, y_train)\n",
        "dev_predictions_three = model.predict(dev_tfidf_matrix_three)\n",
        "SVM_accuracy_three = accuracy_score(y_dev, dev_predictions_three)\n",
        "print(f\"SVM Accuracy for Combination three: {SVM_accuracy_three}\")\n",
        "\n",
        "ClassificationReport_three = classification_report(y_dev, dev_predictions_three)\n",
        "print(f\"\\nCombination three Classification Report\\n: {ClassificationReport_three}\")\n",
        "\n",
        "#Evaluate on Test set\n",
        "test_predictions_three = model.predict(test_tfidf_matrix_three)\n",
        "logistic_regresion_test_accuracy_three = accuracy_score(y_test, test_predictions_three)\n",
        "print(f\"Logistic Regression Test Accuracy for Combination three: {logistic_regresion_test_accuracy_three}\")\n",
        "\n",
        "ClassificationReport_test_three = classification_report(y_test, test_predictions_three)\n",
        "print(f\"\\nCombination three Classification Report\\n: {ClassificationReport_test_three}\")"
      ],
      "metadata": {
        "id": "bqQAEFgyTpBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5phJ0j4K-8O"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import random\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "def logistic_regression_hyperparameter(train_matrix, dev_matrix, test_matrix, y_train, y_dev, y_test):\n",
        "    # Define hyperparameter grid\n",
        "    hyperparameters = {\n",
        "        'C': [0.01, 0.1, 1, 10, 100],\n",
        "        'penalty': ['l2'],\n",
        "        'solver': ['lbfgs'],\n",
        "        'max_iter': [100, 200, 300]  # Add a range of max_iter values\n",
        "    }\n",
        "\n",
        "    best_accuracy = 0\n",
        "    best_hyperparameters = None\n",
        "\n",
        "    # Try 5 combinations\n",
        "    for _ in range(5):\n",
        "        # Randomly select hyperparameters\n",
        "        current_hyperparameters = {\n",
        "            'C': random.choice(hyperparameters['C']),\n",
        "            'penalty': random.choice(hyperparameters['penalty']),\n",
        "            'solver': random.choice(hyperparameters['solver']),\n",
        "            'max_iter': random.choice(hyperparameters['max_iter'])\n",
        "        }\n",
        "\n",
        "        # Create and train logistic regression model\n",
        "        model = LogisticRegression(**current_hyperparameters)\n",
        "        model.fit(train_matrix, y_train)\n",
        "\n",
        "        # Evaluate on dev matrix\n",
        "        y_dev_pred = model.predict(dev_matrix)\n",
        "        dev_accuracy = accuracy_score(y_dev, y_dev_pred)\n",
        "\n",
        "        # Check if current combination is the best\n",
        "        if dev_accuracy > best_accuracy:\n",
        "            best_accuracy = dev_accuracy\n",
        "            best_hyperparameters = current_hyperparameters\n",
        "\n",
        "    # Apply best hyperparameters on test set\n",
        "    best_model = LogisticRegression(**best_hyperparameters)\n",
        "    best_model.fit(train_matrix, y_train)\n",
        "    y_test_pred = best_model.predict(test_matrix)\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    ClassificationReport = classification_report(y_test, y_test_pred)\n",
        "\n",
        "    print(\"Dev Set Accuracy (Best):\", best_accuracy)\n",
        "    print(\"Test Set Accuracy:\", test_accuracy)\n",
        "    print(\"\\nClassification report\\n\", ClassificationReport)\n",
        "\n",
        "    return best_hyperparameters, best_accuracy, test_accuracy\n",
        "\n",
        "logistic_regression_hyperparameter(train_tfidf_matrix_two, dev_tfidf_matrix_two, test_tfidf_matrix_two, y_train, y_dev, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pnKVPYKTPV4"
      },
      "outputs": [],
      "source": [
        "def svm_hyperparameter(train_matrix, dev_matrix, test_matrix, y_train, y_dev, y_test):\n",
        "    # Define hyperp__arameter grid\n",
        "    hyperparameters = {\n",
        "        'C': [0.1, 1, 10, 100],\n",
        "        'kernel': ['linear', 'rbf'],\n",
        "        'gamma': ['scale', 'auto']\n",
        "    }\n",
        "\n",
        "    best_accuracy = 0\n",
        "    best_hyperparameters = None\n",
        "\n",
        "    # Try 5 combinations\n",
        "    for i in range(5):\n",
        "        # Randomly select hyperparameters\n",
        "        current_hyperparameters = {\n",
        "            'C': random.choice(hyperparameters['C']),\n",
        "            'kernel': random.choice(hyperparameters['kernel']),\n",
        "            'gamma': random.choice(hyperparameters['gamma'])\n",
        "        }\n",
        "\n",
        "        # Create and train SVM model\n",
        "        model = SVC(**current_hyperparameters)\n",
        "        model.fit(train_matrix, y_train)\n",
        "\n",
        "        # Evaluate on dev matrix\n",
        "        y_dev_pred = model.predict(dev_matrix)\n",
        "        dev_accuracy = accuracy_score(y_dev, y_dev_pred)\n",
        "\n",
        "        # Check if current combination is the best\n",
        "        if dev_accuracy > best_accuracy:\n",
        "            best_accuracy = dev_accuracy\n",
        "            best_hyperparameters = current_hyperparameters\n",
        "\n",
        "    # Apply best hyperparameters on test set\n",
        "    best_model = SVC(**best_hyperparameters)\n",
        "    best_model.fit(train_matrix, y_train)\n",
        "    y_test_pred = best_model.predict(test_matrix)\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    ClassificationReport = classification_report(y_test, y_test_pred)\n",
        "\n",
        "    print(\"\\nBest Hyperparameters:\", best_hyperparameters)\n",
        "    print(\"Dev Set Accuracy (Best):\", best_accuracy)\n",
        "    print(\"Test Set Accuracy:\", test_accuracy)\n",
        "    print(\"\\nClassification report\\n\", ClassificationReport)\n",
        "\n",
        "    return best_hyperparameters, best_accuracy, test_accuracy\n",
        "\n",
        "svm_hyperparameter(train_tfidf_matrix_two, dev_tfidf_matrix_two, test_tfidf_matrix_two, y_train, y_dev, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "id": "8ndQvBrQk_dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate -U"
      ],
      "metadata": {
        "id": "zQlltfDWlTjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]>=0.20.1\n"
      ],
      "metadata": {
        "id": "nBdzTjbYnTOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BERT\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='/content/drive/MyDrive/bert',          # output directory\n",
        "    num_train_epochs=3,              # total number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='/content/drive/MyDrive/bertlogs',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=X_train,               # training dataset\n",
        "    eval_dataset=X_dev                   # evaluation dataset\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "model.save()\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "J2-O9EPslkwL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}